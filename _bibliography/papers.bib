---
---

@article{zhang2025dpt,
title={Leveraging Dual Process Theory in Language Agent Framework for Real-time Simultaneous Human-AI Collaboration}, 
author={Shao Zhang* and Xihuai Wang* and Wenhao Zhang and Chaoran Li and Junru Song and Tingyu Li and Lin Qiu and Xuezhi Cao and Xunliang Cai and Wen Yao and Weinan Zhang and Xinbing Wang and Ying Wen},
year={2025},
url={https://arxiv.org/abs/2502.11882}, 
pdf={https://arxiv.org/abs/2502.11882.pdf}, 
bibtex_show = {true},
abbr={Language Agent},
selected={true},
journal = {Preprint Under Review},
code={https://github.com/sjtu-marl/DPT-Agent},
abstract = {Agents built on large language models (LLMs) have excelled in turn-by-turn human-AI collaboration but struggle with simultaneous tasks requiring real-time interaction. Latency issues and the challenge of inferring variable human strategies hinder their ability to make autonomous decisions without explicit instructions. Through experiments with current independent System 1 and System 2 methods, we validate the necessity of using Dual Process Theory (DPT) in real-time tasks. We propose DPT-Agent, a novel language agent framework that integrates System 1 and System 2 for efficient real-time simultaneous human-AI collaboration. DPT-Agent's System 1 uses a Finite-state Machine (FSM) and code-as-policy for fast, intuitive, and controllable decision-making. DPT-Agent's System 2 integrates Theory of Mind (ToM) and asynchronous reflection to infer human intentions and perform reasoning-based autonomous decisions. We demonstrate the effectiveness of DPT-Agent through further experiments with rule-based agents and human collaborators, showing significant improvements over mainstream LLM-based frameworks. To the best of our knowledge, DPT-Agent is the first language agent framework that achieves successful real-time simultaneous human-AI collaboration autonomously. Code of DPT-Agent can be found in https://github.com/sjtu-marl/DPT-Agent.}
}

@article{wang2023zsceval,
title={ZSC-Eval: An Evaluation Toolkit and Benchmark for Multi-agent Zero-shot Coordination},
author={Xihuai Wang and Shao Zhang and Wenhao Zhang and Wentao Dong and Jingxiao Chen and Ying Wen and Weinan Zhang},
year={2024},
selected={true},
pdf={https://arxiv.org/pdf/2310.05208.pdf},
abbr = {MARL Generalization},
journal={38th NeurIPS Dataset and Benchmark Track},
code={https://github.com/sjtu-marl/zsc-eval}
}

@article{
wang2023order,
abbr={MARL Efficiency},
title={Order Matters: Agent-by-agent Policy Optimization},
author={Xihuai Wang and Zheng Tian and Ziyu Wan and Ying Wen and Jun Wang and Weinan Zhang},
journal={11th ICLR},
year={2023},
url={https://openreview.net/forum?id=Q-neeWNVv1},
selected={true},
pdf={https://arxiv.org/pdf/2302.06205.pdf},
code={https://github.com/xihuai18/A2PO-ICLR2023}
}

@article{Wang2022ModelbasedMR,
title={Model-based Multi-agent Reinforcement Learning: Recent Progress and Prospects},
author={Xihuai Wang and Zhicheng Zhang and Weinan Zhang},
journal={ArXiv},
abbr={MARL Efficiency},
year={2022},
volume={abs/2203.10603},
pdf={https://arxiv.org/pdf/2203.10603.pdf}
}
@article{Zhang2021ModelbasedMP,
abbr={MARL Efficiency},
title={Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise Rollouts},
author={Weinan Zhang and Xihuai Wang and Jian Shen and Ming Zhou},
journal={30th IJCAI},
year={2021},
selected={true},
pdf={https://arxiv.org/pdf/2105.03363.pdf},
code={https://github.com/xihuai18/AORPO}
}
